{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f23641",
   "metadata": {},
   "source": [
    "# plugin\n",
    "\n",
    "> Plugin implementation for NVIDIA GPU monitoring using nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7be84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b21fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import psutil\n",
    "import subprocess\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from cjm_infra_plugin_system.plugin_interface import MonitorPlugin\n",
    "from cjm_infra_plugin_system.core import SystemStats\n",
    "from cjm_plugin_system.utils.validation import dataclass_to_jsonschema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29bc519",
   "metadata": {},
   "source": [
    "## NvidiaMonitorPlugin\n",
    "\n",
    "NVIDIA GPU monitoring plugin using `nvitop` library. Provides real-time hardware telemetry for:\n",
    "\n",
    "- **GPU Memory**: Free, used, and total VRAM across all visible devices\n",
    "- **GPU Utilization**: Compute load percentage\n",
    "- **System RAM**: Via psutil for cross-platform support\n",
    "- **CPU**: Overall utilization percentage\n",
    "\n",
    "Falls back to `nvidia-smi` if `nvitop` is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NvidiaMonitorPlugin(MonitorPlugin):\n",
    "    \"\"\"NVIDIA System Monitor using nvitop.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the NVIDIA monitor plugin.\"\"\"\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config = {}\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:  # Plugin identifier\n",
    "        \"\"\"Plugin name.\"\"\"\n",
    "        return \"sys-mon-nvidia\"\n",
    "    \n",
    "    @property\n",
    "    def version(self) -> str:  # Plugin version\n",
    "        \"\"\"Plugin version.\"\"\"\n",
    "        return \"1.0.0\"\n",
    "\n",
    "    def initialize(\n",
    "        self,\n",
    "        config: Optional[Dict[str, Any]] = None  # Configuration dictionary\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize or reconfigure the plugin.\"\"\"\n",
    "        self.config = config or {}\n",
    "        self.logger.info(\"NvidiaMonitor initialized\")\n",
    "\n",
    "    def get_config_schema(self) -> Dict[str, Any]:  # JSON Schema\n",
    "        \"\"\"Return JSON Schema for configuration.\"\"\"\n",
    "        return {}  # No config needed for monitoring\n",
    "\n",
    "    def get_current_config(self) -> Dict[str, Any]:  # Current config\n",
    "        \"\"\"Return current configuration.\"\"\"\n",
    "        return self.config\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _get_gpu_info_internal(self) -> Dict[str, Any]:  # Raw GPU data\n",
    "        \"\"\"Check for GPU availability and get info using nvitop.\"\"\"\n",
    "        gpu_info = {'available': False, 'type': 'None', 'details': {}, 'processes': []}\n",
    "        \n",
    "        try:\n",
    "            import nvitop\n",
    "            from nvitop import Device, GpuProcess, NA\n",
    "\n",
    "            devices = Device.all()\n",
    "            if devices:\n",
    "                gpu_info['available'] = True\n",
    "                gpu_info['type'] = 'NVIDIA'\n",
    "\n",
    "                for i, device in enumerate(devices):\n",
    "                    # Memory\n",
    "                    mem_total = device.memory_total()\n",
    "                    mem_used = device.memory_used()\n",
    "                    mem_free = device.memory_free()\n",
    "                    \n",
    "                    # Convert NA to 0\n",
    "                    if mem_total == NA: mem_total = 0\n",
    "                    if mem_used == NA: mem_used = 0\n",
    "                    if mem_free == NA: mem_free = 0\n",
    "\n",
    "                    gpu_info['details'][f'gpu_{i}'] = {\n",
    "                        'name': device.name(),\n",
    "                        'memory_total': mem_total // (1024**2),\n",
    "                        'memory_used': mem_used // (1024**2),\n",
    "                        'memory_free': mem_free // (1024**2),\n",
    "                        'utilization': device.gpu_utilization() if device.gpu_utilization() != NA else 0\n",
    "                    }\n",
    "        except ImportError:\n",
    "            # nvitop not available, fallback to nvidia-smi\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    ['nvidia-smi', '--query-gpu=name,memory.total,memory.used,memory.free,utilization.gpu',\n",
    "                     '--format=csv,noheader,nounits'],\n",
    "                    capture_output=True, text=True, timeout=2\n",
    "                )\n",
    "                if result.returncode == 0:\n",
    "                    lines = result.stdout.strip().split('\\n')\n",
    "                    for i, line in enumerate(lines):\n",
    "                        parts = [p.strip() for p in line.split(',')]\n",
    "                        if len(parts) >= 5:\n",
    "                            gpu_info['available'] = True\n",
    "                            gpu_info['type'] = 'NVIDIA'\n",
    "                            gpu_info['details'][f'gpu_{i}'] = {\n",
    "                                'name': parts[0],\n",
    "                                'memory_total': int(float(parts[1])) if parts[1] and parts[1] != 'N/A' else 0,\n",
    "                                'memory_used': int(float(parts[2])) if parts[2] and parts[2] != 'N/A' else 0,\n",
    "                                'memory_free': int(float(parts[3])) if parts[3] and parts[3] != 'N/A' else 0,\n",
    "                                'utilization': int(float(parts[4])) if parts[4] and parts[4] != 'N/A' else 0,\n",
    "                            }\n",
    "            except (subprocess.TimeoutExpired, FileNotFoundError, Exception):\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error checking GPU: {e}\")\n",
    "\n",
    "        return gpu_info\n",
    "\n",
    "    def execute(\n",
    "        self,\n",
    "        command: str = \"get_system_status\",  # Command to execute\n",
    "        **kwargs\n",
    "    ) -> Dict[str, Any]:  # SystemStats as dictionary\n",
    "        \"\"\"Collect stats and return standardized SystemStats dictionary.\"\"\"\n",
    "        if command != \"get_system_status\":\n",
    "            raise ValueError(f\"Unknown command: {command}\")\n",
    "        \n",
    "        # 1. Get Host CPU/RAM (psutil)\n",
    "        vm = psutil.virtual_memory()\n",
    "        \n",
    "        # 2. Get GPU Data\n",
    "        gpu_raw = self._get_gpu_info_internal()\n",
    "        \n",
    "        # 3. Aggregate GPU Stats for the Scheduler\n",
    "        total_vram_free = 0\n",
    "        total_vram_total = 0\n",
    "        total_vram_used = 0\n",
    "        max_load = 0\n",
    "        \n",
    "        if gpu_raw['available']:\n",
    "            for key, det in gpu_raw['details'].items():\n",
    "                total_vram_free += det.get('memory_free', 0)\n",
    "                total_vram_total += det.get('memory_total', 0)\n",
    "                total_vram_used += det.get('memory_used', 0)\n",
    "                max_load = max(max_load, det.get('utilization', 0))\n",
    "\n",
    "        # 4. Return Standardized Object as dict\n",
    "        stats = SystemStats(\n",
    "            cpu_percent=psutil.cpu_percent(),\n",
    "            memory_used_mb=vm.used / (1024**2),\n",
    "            memory_total_mb=vm.total / (1024**2),\n",
    "            memory_available_mb=vm.available / (1024**2),\n",
    "            gpu_type=gpu_raw['type'],\n",
    "            gpu_free_memory_mb=float(total_vram_free),\n",
    "            gpu_total_memory_mb=float(total_vram_total),\n",
    "            gpu_used_memory_mb=float(total_vram_used),\n",
    "            gpu_load_percent=float(max_load),\n",
    "            details=gpu_raw\n",
    "        )\n",
    "        return stats.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726eeea",
   "metadata": {},
   "source": [
    "### Usage Example\n",
    "\n",
    "```python\n",
    "# Direct usage (for testing)\n",
    "plugin = NvidiaMonitorPlugin()\n",
    "plugin.initialize()\n",
    "stats = plugin.execute()\n",
    "print(f\"GPU Free: {stats['gpu_free_memory_mb']}MB\")\n",
    "print(f\"RAM Available: {stats['memory_available_mb']}MB\")\n",
    "```\n",
    "\n",
    "### Integration with PluginManager\n",
    "\n",
    "```python\n",
    "from cjm_plugin_system.core.manager import PluginManager\n",
    "from cjm_plugin_system.core.scheduling import SafetyScheduler\n",
    "\n",
    "manager = PluginManager(scheduler=SafetyScheduler())\n",
    "manager.load_all()\n",
    "\n",
    "# Register this plugin as the system monitor\n",
    "manager.register_system_monitor(\"cjm-system-monitor-nvidia\")\n",
    "\n",
    "# Now scheduling checks will use real GPU stats\n",
    "result = manager.execute_plugin(\"whisper-local\", audio=\"/path/to/audio.wav\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
